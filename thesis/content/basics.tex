\chapter{Mathematical Basics}

\autoref{sec:basics:HJT} derives the \Riccati equation in the context of optimal control following \cite{Locatelli2011},
and mentions other linear matrix equations relevant to this thesis.
Afterwards, \autoref{sec:basics:smw} gives a brief overview on the Sherman-Morrison-Woodbury formula
as an efficient strategy to solve systems having the structure of a low-rank update.

... \ac{DRE} arising in optimal control.

\section{Hamilton-Jacobi Theory}
\label{sec:basics:HJT}

\subsection{Finite Control Horizon}

Consider the \ac{OCP}
\begin{equation}
  \everymath{\displaystyle}
  \begin{array}{cl}
    \min_u & \int_{t_0}^{t_f} \ell\big(t, x(t), u(t)\big) \dt + m\big(t_f, x(t_f)\big) \\
    \text{s.t.} & \dot{x} = f(t,x,u), \enspace x(t_0) = x_0
  \end{array}
  \label{eq:basics:OCP}
\end{equation}
using \emph{state}~$x(t)\in\R^n$, system \emph{input} or \emph{control}~$u(t)\in\R^m$,
and scalar cost functions~$\ell$ and~$m$.
Following \cite{Locatelli2011},
a sufficient condition for
an optimal control $u^*$ solving \eqref{eq:basics:OCP} may be stated by means of a
continuously differentiable
\emph{value function}~$V:\R\times\R^n\to\R$ satisfying the \emph{\ac{HJE}}
\begin{equation}
  V_t(t,z) + \Ham\big(t,z,u^h,V_z(t,z)^\T \big) = 0
  \label{eq:basics:HJE}
\end{equation}
for any $z\in\R^n$,
as well as
\begin{equation}
  V(t_f,z) = m(t_f,z)
  \label{eq:basics:HJE:condition}
\end{equation}
for all admissible final events $(t_f,z)$.
$V_t$ and $V_z$ denote the partial derivatives of $V$,
the \emph{Hamiltonian} $\Ham:\R\times\R^n\times\R^m\times\R^n\to\R$ is given by
\begin{equation}
\label{eq:basics:Hamiltonian}
  \Ham(t,z,u,\lambda) := \ell(t,z,u) + \lambda^\T f(t,z,u)
\end{equation}
and $u^h := u^h\big(t,z,V_z(t, z)^\T\big)$ denotes the \Ham-minimizing control.\footnote{%
  It is $\Ham(t, z, u^h, \lambda) < \Ham(t, z, u, \lambda)$ for $u \neq u^h = u^h(t, z, \lambda)$.
  \Ham{} is said to be \emph{regular} if $u^h$ exists and is unique for any $t, z, \lambda$.
  Here, this is always assumed to be the case.
}
Namely, a control $u^*$ is optimal if it fulfills the feedback law
\begin{equation}
\label{eq:basics:HJ:feedback}
  u^*(t) = u^h\big(t, x(t), V_z(t,z)^\T |_{z=x(t)} \big)
\end{equation}
where $x$ is determined by $\dot x = f(t, x, u^*)$ and $x(t_0) = x_0$,
\cf~\cite[Corollary~2.1]{Locatelli2011}.

In the remainder of the section,
we apply this theory to the \ac{LQR} tracking problem
consisting of a linear system and quadratic cost functions.
We only give a very brief outline of the ideas leading to a \ac{DRE}
following \cite[Remarks~3.3 and~3.6]{Locatelli2011} and \cite[Section~3.2.2]{Lang2017},
to which the reader may refer to for more details.

Many applications can be expressed by means of a
linear \emph{(standard) state-space system}
\begin{equation}
\label{eq:basics:system:standard}
\left\{
\begin{aligned}
  \dot x &= Ax + Bu \\
  y &= Cx
\end{aligned}
\right.
\end{equation}
consisting of, again, \emph{state} $x(t)\in\R^n$ and \emph{input} or \emph{control} $u(t)\in\R^m$.
$y(t) \in\R^q$ with $q \ll n$ denotes the system's \emph{output},
as for most applications it is impossible to measure the whole state $x$.
The dynamics of the system are described by the
\emph{state-space matrix} $A(t) \in \Rnn$,
\emph{input map} $B(t) \in\R^{n \times m}$,
and
\emph{output map} $C(t) \in\R^{q\times n}$.
Further, let the cost functions be given by the squared weighted norms
\begin{equation}
\label{eq:basics:LQR:cost}
\begin{aligned}
  \ell(t, x, u)
  &= \tfrac{1}{2}\norm{y - \hat y}_Q^2 + \tfrac{1}{2}\norm{u}_R^2 \\
  m(t, x)
  &= \tfrac{1}{2} \norm{y - \hat y}_S^2
\end{aligned}
\end{equation}
for symmetric positive-definite weight matrices
$Q\in\R^{q\times q}$,
$R\in\R^{m\times m}$, and
$S\in\R^{q\times q}$.
$\hat y(t) \in\R^q$ describes a desired trajectory the modeled system should follow,
\eg by measurements of a real system, or economic requirements of the technical process behind it.
The system~\eqref{eq:basics:system:standard} is referred to as \ac{LTI}
if the \emph{system matrices} $A(t), B(t), C(t)$ are constant for $t\in [t_0,t_f]$,
and \ac{LTV} otherwise.
We restrict ourselves to \ac{LTI} and \emph{controllable} systems,
\todo{Is this notion of \enquote{controllable} correct?}
\ie for any given $(t_0, x_0)$ and $(t_1, x_1)$, $t_1 > t_0$,
there exists a bounded control $u(\optional{})$ such that $x(t_1; t_0, x_0, u(\optional{})) = x_1$.

The Hamiltonian~\eqref{eq:basics:Hamiltonian} is then given by
\begin{equation*}
  \Ham(t,z,u,\lambda) =
  \onehalf \norm{Cz - \hat y}_Q^2 +
  \onehalf \underbrace{
    \norm{u}_R^2
  }_{u^\T R u}
  {} +
  \lambda^\T (Az + Bu)
  ,
\end{equation*}
causing the \Ham-minimizing control $u^h$ to be defined by
\begin{equation*}
  \Ham_u = Ru^h + B^\T \lambda \overset{!}{=} 0,
  \qquad
  \Ham_{uu} = R \overset{!}{\succ} 0.
\end{equation*}
The second order criterion is fulfilled by construction,
and ensures the existence of $R^{-1}$.
Thus, the first order criterion implies
\begin{equation}
\label{eq:basics:LQR:uh}
  u^h(t, z, \lambda) = -R^{-1} B^\T \lambda
  .
\end{equation}

%What follows is a very brief outline of the key ideas leading to a \ac{DRE} associated to the \ac{OCP} for \ac{LQR}.
%It is based on \cite[Remarks~3.3 and~3.6]{Locatelli2011} and \cite[Section~3.2.2]{Lang2017}, to which we refer the reader for more details.
Making the ansatz
\begin{equation}
\label{eq:basics:LQR:ansatz}
  V(t,z) := \onehalf z^\T X(t) z + w(t)^\T z + v(t)
\end{equation}
for the value function,
its partial derivates read
\begin{equation}
\begin{aligned}
  V_t &= \onehalf z^\T \dot X z + \dot w^\T z + \dot v \\
  V_z &= z^\T X + w^\T
  .
\end{aligned}
\end{equation}
Substituting the above, $u^h(t, z, V_z^\T)$ based on \eqref{eq:basics:LQR:uh},
as well as the scalar identity
\begin{equation}
  z^T X A z = \onehalf \Big( z^T X A z + \big( z^\T X A z \big)^\T \Big)
\end{equation}
into the \ac{HJE}~\eqref{eq:basics:HJE},
and regrouping based on the order of $z$ yields
\begin{subequations}
\label{eq:basics:LQR:HJE}
\begin{align}
  0 ={}
\label{eq:basics:LQR:HJE:X}
  & \tfrac{1}{2} z^\T \big( \dot X + C^\T Q C + X A + A^\T X^\T - X B R^{-1} B^\T X^\T \big) z \\
  & + \big( \dot w^\T + w^\T A - w^\T B R^{-1} B^\T X^\T - \hat y^\T Q C \big) z \\
  & + \big( \dot v - \tfrac{1}{2} \big( w^\T B R^{-1} B^\T w - \hat y Q \hat y \big) \big)
\end{align}
\end{subequations}
while the final condition~\eqref{eq:basics:HJE:condition} reads
\begin{equation}
\label{eq:basics:LQR:condition}
\begin{aligned}
  \MoveEqLeft
  \onehalf z(t_f)^\T X(t_f) z(t_f) + w^\T (t_f) z(t_f) + v(t_f)
  \\
  &= \onehalf z(t_f) \big( C^\T S C \big) z(t_f)
  - \big( \hat y(t_f)^\T S C \big) z(t_f)
  + \big( \onehalf \hat y(t_f)^\T S \hat y(t_f) \big)
  .
\end{aligned}
\end{equation}

Sufficient conditions are obtained by letting \eqref{eq:basics:LQR:HJE} be the (multivariate) zero polynomial in $z$,
and comparing the coefficients of the therms in $z$ in \eqref{eq:basics:LQR:condition}.
Upon noting that if $X$ fulfills the dynamics of \eqref{eq:basics:LQR:HJE:X}, so does $X^\T$,
this leads to a \ac{DRE} in $X(t)\in\Rnn$,
\begin{equation}
\label{eq:basics:LQR:DRE:backwards}
\left\{
\begin{aligned}
  \dot X &= -\big( C^\T Q C + X A + A^\T X - X B R^{-1} B^\T X \big) \\
  X(t_f) &= C^\T S C
  ,
\end{aligned}
\right.
\end{equation}
an \ac{ODE} in $w(t)\in\R^n$,
the so-called \emph{adjoint state equation},
\begin{equation}
\left\{
\begin{aligned}
  \dot w &= - \big( A^\T - X B R^{-1} B^\T \big) w + C^\T Q \hat y \\
  w(t_f) &= - C^\T S \hat y(t_f)
  ,
\end{aligned}
\right.
\end{equation}
and another \ac{ODE} in $v(t)\in\R$,
\begin{equation}
\left\{
\begin{aligned}
  \dot v &= \onehalf ( w^\T B R^{-1} B^\T w - \hat y Q \hat y) \\
  v(t_f) &= \onehalf \hat y(t_f)^\T S \hat y(t_f)
  ,
\end{aligned}
\right.
\end{equation}
all to be solved backwards in time $t \in [t_0,t_f]$.

However, the optimal control $u^*$ given by the feedback law \eqref{eq:basics:HJ:feedback},
\begin{equation}
\label{eq:basics:LQR:u*}
\begin{aligned}
  u^*(t)
  &= - R^{-1} B^\T V_z\big(t, x(t)\big)^\T \\
  &= - \underbrace{
    R^{-1} B^\T \big( X(t)
  }_{=\mathrlap{:K(t)}}
  x(t) + w(t) \big)
  %x(t) - R^{-1} B^\T w(t)
\end{aligned}
\end{equation}
does not require $v$.
The overall cost to compute $u^*$ is dominated by solving the \ac{DRE}~\eqref{eq:basics:LQR:DRE:backwards}.
Furthermore, the full solution $X(t)\in\Rnn$ is not needed.
Rather, it suffices to store the so-called \emph{gain-} or \emph{feedback matrix} $K(t) \in\R^{m\times n}$.
Since typically $m \ll n$, this has a major impact on the storage requirements.

\todo[inline]{Maybe discuss uniqueness of $u^*$. It should be possible to adapt \cite[Remark~3.2]{Locatelli2011} to this case.}

\begin{remark}
  A \emph{generalized} linear state-space system
  \begin{equation}
  \left\{
  \begin{aligned}
    E \dot x &= Ax + Bu \\
    y &= Cx
  \end{aligned}
  \right.
  \end{equation}
  with invertible \emph{mass matrix} $E(t)\in\Rnn$ is equivalent to the
  standard state-space system
  \begin{equation}
  \left\{
  \begin{aligned}
    \dot{\tilde x} &= \tilde A \tilde x + Bu \\
    y &= \tilde C \tilde x
  \end{aligned}
  \right.
  \end{equation}
  where $\tilde x := E x$, $\tilde A := A E^{-1}$ and $\tilde C := C E^{-1}$.
  By applying the theory above
  and avoiding the inversion of $E$ in the resulting equations,
  one obtains the generalized \ac{DRE}
  \begin{equation}
  \left\{
  \begin{aligned}
    E^\T \dot X E &= -\big( C^\T Q C + E^\T X A + A^\T X E - E^\T X B R^{-1} B^\T X E \big) \\
    E^\T X(t_f) E &= C^\T S C
    ,
  \end{aligned}
  \right.
  \end{equation}
  and the generalized adjoint state equation
  \begin{equation}
  \left\{
  \begin{aligned}
    E^\T \dot w &= - \big( A^\T - E^\T X B R^{-1} B^\T \big) w + C^\T Q \hat y \\
    E^\T w(t_f) &= - C^\T S \hat y(t_f)
    .
  \end{aligned}
  \right.
  \end{equation}
  The feedback matrix $K$ is then given by
  \begin{equation}
    K(t) = R^{-1} B^\T X(t) E
    .
  \end{equation}
\end{remark}

\begin{example}[Steel Profile]
  The steel profile benchmark \cite{morwiki_steel} goes back to \cite{Benner2005}.
  It is a generalized system that has $m=7$ controls and $q=6$ outputs.
  We'll use the variant having $n=371$ state variables.
  Furthermore,
  \begin{equation*}
    Q = I_q,
    \qquad
    R = I_m,
    \qquad
    S = \tfrac{1}{100} I_q,
  \end{equation*}
  such that $K(t) = B^\T X(t) E$.
\end{example}

Within this thesis we'll only consider the \ac{LTI} case with invertible $E$.
In fact, most computations will be performed for the problem above.
Therefore, $Q$ and $R$ are assumed to be identity matrices of appropriate size.

\subsection{Infinite Control Horizon}
% cf \cite[Remark~3.13, Theorem~3.3]{Locatelli2011}

Consider the \ac{OCP} for \ac{LQR} over an infinite time horizon,
\begin{equation}
\label{eq:basics:OCP'}
  \everymath{\displaystyle}
  \begin{array}{cl}
    \min_u & \int_{t_0}^{\infty} \ell\big(t, x(t), u(t)\big) \dt \\
    \text{s.t.} & \dot{x} = Ax + Bu, \enspace x(t_0) = x_0
    .
  \end{array}
\end{equation}
For
$
  \ell(t, x, u) = \onehalf \norm{Cx - \hat y(t)}_Q^2 + \onehalf \norm{u}_R^2
$
as in \eqref{eq:basics:LQR:cost},
following the proof of \cite[Theorem~3.2]{Locatelli2011},
the optimal control is given by
\begin{equation}
  u^*(t) = - R^{-1} B^\T \big( \bar X(t) x(t) + \bar w(t) \big)
\end{equation}
for some $\bar w(t)$,
where $\bar X(t) := \lim_{t_f \to\infty} X(t; t_f)$
and $X(\optional{};t_f)$ is the solution to \ac{DRE}~\eqref{eq:basics:LQR:DRE:backwards}
having the boundary value $X(t_f; t_f) = 0$. % t_f < \infty
By \cite[Theorem~3.3]{Locatelli2011},
$\bar X(t) \equiv \bar X$ is constant.
Hence, its derivative is zero such that $\bar X$ is a solution to the \ac{ARE}
\begin{equation}
\label{eq:basics:LQR:ARE}
  C^\T Q C + \bar X A + A^\T \bar X - \bar X B R^{-1} B^\T \bar X = 0
  .
\end{equation}
Compare this to the feedback law \eqref{eq:basics:LQR:u*} for a finite time horizon,
where $X(t)$ is time-dependent.
To summarize:

\begin{proposition}[LQR over Infinite Time Horizon]
\label{thm:basics:dre-limit-are:backwards}
  The value $X(t_0; t_f)$ of the solution $X(\optional{}; t_f)$ to the \ac{DRE}~\eqref{eq:basics:LQR:DRE:backwards}
  having the boundary value $X(t_f; t_f) = C^\T S C =: X_f$
  converges to
  \begin{equation}
    \lim_{t_f\to\infty} X(t_0; t_f) = \bar X + X_f
  \end{equation}
  where $\bar X$ is the solution to \ac{ARE}~\eqref{eq:basics:LQR:ARE}.
\end{proposition}
\begin{proof}
  Define $\hat X(t) := X(t; t_f) - X_f$,
  which is the solution to \ac{DRE}~\eqref{eq:basics:LQR:DRE:backwards} having boundary value $\hat X(t_f) = 0$.
  Following the proof of \cite[Theorem~3.3]{Locatelli2011},
  $\hat X(t_0)$ converges to $\bar X$ for $t_f\to\infty$.
  Therefore, $X(t_0, t_f) = \hat X(t_0) + X_f \to \bar X + X_f$.
\end{proof}

\section{Reformulating Problems Forward in Time}

As mentioned previously, the \ac{DRE}~\eqref{eq:basics:LQR:DRE:backwards} has to be solved backwards in time.
It is common practice to instead formulate it forward in time by defining
\begin{equation}
  \tilde X(t) := X(t_f - t + t_0)
\end{equation}
such that
\begin{equation}
\begin{gathered}
  \dot{\tilde X}(t)
  = - \dot X(t_f - t + t_0)
  = + \big( C^\T Q C + A^\T \tilde X(t) + \tilde X(t) A - \tilde X(t) B R^{-1} B^\T \tilde X(t) \big)
  \\
  \tilde X(t_0)
  = X(t_f - t_0 + t_0)
  = X(t_f)
  = C^\T S C
\end{gathered}
\end{equation}
and still $t \in [t_0, t_f]$.
Overall,
\begin{equation}
%\tag{\ref*{eq:basics:LQR:DRE:backwards}'}
\label{eq:basics:LQR:DRE:forwards}
\left\{
\begin{aligned}
  \dot{\tilde X} &= C^\T Q C + A^\T \tilde X + \tilde X A - \tilde X B R^{-1} B^\T \tilde X \\
  \tilde X(t_0) &= C^\T S C
  .
\end{aligned}
\right.
\end{equation}
As both variants of the \ac{DRE},
\eqref{eq:basics:LQR:DRE:backwards} and
\eqref{eq:basics:LQR:DRE:forwards},
may easily be transformed into one another,
the notation $A, B, C, X$ is used for both in this thesis.

\begin{corollary}[LQR over Infinite Time Horizon]
\label{thm:basics:dre-limit-are}
  The solution $\tilde X(t)$ to the \ac{DRE}~\eqref{eq:basics:LQR:DRE:forwards}
  converges to
  \begin{equation}
    \lim_{t\to\infty} \tilde X(t) = \bar X + C^\T S C
    ,
  \end{equation}
  where $\bar X$ is the solution to \ac{ARE}~\eqref{eq:basics:LQR:ARE}.
\end{corollary}
\begin{proof}
  Follows from \autoref{thm:basics:dre-limit-are:backwards} with the direction of time reversed,
  $\lim \tilde X(t_f) = \lim X(t_0; t_f) = \bar X + C^\T S C$ for $t_f\to\infty$.
\end{proof}

\subsection{Alternative: Optimal Control Over an Infinite Horizon}

% cf \cite[Remark~3.13, Theorem~3.3]{Locatelli2011}

\begin{proposition}[LQR over Infinite Time Horizon]
\label{thm:basics:dre-limit-are}
  The solution $X(t)$ to the \ac{DRE}~\eqref{eq:basics:LQR:DRE:forwards}
  converges to
  \begin{equation}
    \lim_{t\to\infty} X(t) = \bar X + C^\T S C
    ,
  \end{equation}
  where $\bar X$ is the solution of the \ac{ARE}
  \begin{equation}
  %\label{eq:basics:LQR:ARE}
    C^\T Q C + A^\T \bar X + \bar X A - \bar X B R^{-1} B^\T \bar X = 0
    .
  \end{equation}
\end{proposition}
\begin{proof}
  Define $\bar X(t) := X(t) - X(t_0)$,
  which is the solution to \ac{DRE}~\eqref{eq:basics:LQR:DRE:forwards} having initial value $\bar X(t_0) = 0$.
  Following the proof of \cite[Theorem~3.3]{Locatelli2011},
  $\bar X(t)$ converges to $\bar X$ for $t\to\infty$.
  Therefore, $X(t) = \bar X(t) + X(t_0) \to \bar X + X(t_0)$.
\end{proof}

\begin{remark}
  The \ac{OCP}
  \begin{equation}
    \everymath{\displaystyle}
    \begin{array}{cl}
      \min_u & \int_{t_0}^{\infty} \ell\big(t, x(t), u(t)\big) \dt \\
      \text{s.t.} & \dot{x} = Ax + Bu, \enspace x(t_0) = x_0
    \end{array}
  \end{equation}
  may be seen as the limit of \ac{OCP}~\eqref{eq:basics:OCP}
  for \ac{LQR} when $m \equiv 0$ and $t_f \to\infty$.
  For
  \begin{equation}
    \ell(t, x, u) = \onehalf \norm{Cx - \hat y(t)}_Q^2 + \onehalf \norm{u}_R^2
  \end{equation}
  as in \eqref{eq:basics:LQR:cost},
  the optimal control is given by the control law
  \begin{equation}
    u^*(t) = - R^{-1} B^\T \big( \bar X x(t) + \bar w(t) \big)
  \end{equation}
  with $\bar X$ being the limit value from \autoref{thm:basics:dre-limit-are}.
  The exact structure of $\bar w(t)$ is not important for this thesis.
  Compare this to the feedback law \eqref{eq:basics:LQR:u*} for a finite time horizon,
  where $X(t)$ is time-dependent, while here $\bar X$ is not.
\end{remark}

\subsection{Other Related Matrix Equations}

As mentioned in \cite{Dieci1992},
any implicit time-stepping method applied to a (generalized) \ac{DRE} will yield a (generalized) \ac{ARE}
\begin{equation}
\label{eq:basics:ARE}
    A^\T X E + E^\T X A - E^\T X S X E = -W,
    \quad
    W = W^\T
\end{equation}
to be solved at every step.
Some methods, including the Rosenbrock-type methods to be covered in \autoref{sec:ros},
only require a (generalized) \ac{ALE}
\begin{equation}
\label{eq:basics:ALE}
  A^\T X E + E^\T X A = -W,
  \quad
  W = W^\T
\end{equation}
to be solved at every step,
which is a special case of the \ac{ARE}.
\ac{ALE} may be solved \eg using the \ac{ADI} method,
which will be covered in \autoref{sec:ADI}.

\todo[inline]{Quote theorems about existance and uniqueness of solutions}

\begin{theorem}[Solvability of DRE]
  todo
\end{theorem}
\begin{proof}
  todo
\end{proof}

\begin{theorem}[Solvability of ARE]
  todo
\end{theorem}
\begin{proof}
  todo
\end{proof}

\begin{theorem}[Solvability of ALE]
  todo
\end{theorem}
\begin{proof}
  See \eg \cite{Lancaster1995}.
\end{proof}

\section{Sherman-Morrison-Woodbury}
\label{sec:basics:smw}

