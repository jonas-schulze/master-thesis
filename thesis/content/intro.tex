\chapter{Introduction}

Current challenges in science and engineering require a fast iteration on (intermediate) ideas and designs,
which in turn demands highly performant algorithms.
In this context, efficiency may only be a secondary concern.
Meanwhile, modern computer architectures are dominated by parallelism:
multiple cores per CPU,
multiple CPUs per node,
and
multiple nodes per cluster.
Many real-world application can be modeled by \acp{PDE} or \acp{ODE},
which describe the behavior of an underlying system in space and time.
A common strategy is to solve these equations \emph{parallel-in-space},
\ie to distribute the spatial domain onto several CPUs,
which are then usually worked on in lockstep along the time dimension.
This strategy only scales as far as the local problems do not become too small,
due to the communication necessary along the interfaces of spatial sub-domains.
Another strategy is to (also) solve the problem \emph{parallel-in-time},
%\ie to solve the temporal dynamics of the system in parallel.
\ie to distribute the temporal domain onto several CPUs.
An algorithm of the latter strategy is the so-called parareal method~\cite{Lions2001},
which is the focus of this thesis.
%From a pure energy-consumed or efficiency perspective,
From an energy efficiency perspective,
the parareal method is not worth pursuing.
However, as engineering demands fast cycle times,
this method can lead to large speed-ups.

In this thesis, the parareal method shall be applied to the matrix-valued \ac{DRE},
which arises \eg in optimal control and model order reduction.
Discretizations of real-world problems quickly lead to large-scale systems,
for which the solution matrices easily reach thousands of rows and columns.
In order to handle them efficiently,
one uses the problem's inherent rapid decay of singular values
to approximate the solution matrices in a low-rank factorization, see \eg~\cite{Penzl2000,Kuerschner2016,Lang2017}.
This low-rank approach sets this thesis apart from the work of \citeauthor{Koehler2016}~\cite{Koehler2016},
who use a dense parareal scheme.
As the rank of the solution approximation varies in time,
an implementation using well-established frameworks like OpenMPI\footnote{\url{https://www.open-mpi.org/}}
would be more involved.
Since Julia~\cite{Julia} promises to provide a fresh perspective on high-performance computing problems,
this thesis serves as a test project for just that.

The thesis is structured as follows.
\autoref{sec:HJT} gives an overview of the \ac{DRE} arising in optimal control of a linear dynamical system,
and \autoref{sec:matrixeq} presents the general techniques used to handle large-scale problems.
Then, \autoref{sec:ros} shows how to adapt a first-order and a second-order Rosenbrock method to the matrix-valued \ac{DRE}.
Every step of the Rosenbrock method requires the solution of an \mbox{\ac{ALE}},
which may be done using \eg the \ac{ADI} method described in \autoref{sec:ADI}.
This completes the general building blocks of a \ac{DRE} solver.
To improve the performance of the solver,
\autoref{sec:pr} shows how to apply the parareal method to the particular low-rank factorization used in this thesis.
\autoref{sec:impl} describes the implementation of the aforementioned algorithms in the form of two Julia packages,
which have been created for this thesis.
The chapter also presents the numerical results of applying these packages to
a small configuration of the Rail benchmark problem~\cite{morwiki_steel},
which goes back to \citeauthor{Benner2005}~\cite{Benner2005}.
The chapter compares low-rank and dense algorithms in sequential and parareal execution.
Finally, \autoref{sec:conclusion} briefly summarizes the findings and future research or optimization opportunities.

\section*{Hardware and Software Used}

The numerical experiments throughout this thesis were performed
on up to 29 standard nodes (450 cores) of the Linux cluster Mechthild\footnote{\url{https://www.mpi-magdeburg.mpg.de/cluster/mechthild}}
at the Max Planck Institute for Dynamics of Complex Technical Systems in Magdeburg,
each having
two Intel Xeon Skylake Silver 4110 with 8 cores per CPU
and \SI{192}{\giga\byte} of memory,
or on a laptop (MacBook Pro, 13-inch, 2018, macOS 11) having
an
Intel Core i5-8259U with 4 cores and \SI{16}{\giga\byte} of memory.
Each process uses a single Julia thread and,
unless stated otherwise, one BLAS\footnote{%
  \url{http://www.netlib.org/blas/}
}/LAPACK\footnote{%
  \url{http://www.netlib.org/lapack/}
} thread.

\julia{DrWatson.jl}~\cite{DrWatson} was used to assist data management.
The dense \ac{DRE} solvers are built on top of \julia{MatrixEquations.jl}~\cite{MatrixEquations}.
\julia{DifferentialEquations.jl}~\cite{DifferentialEquations} was used for \autoref{example:parareal}.
The figures in this thesis were created with
\julia{Makie.jl}~\cite{Makie} or Ti\emph{k}Z~\cite{TikZ}.
Julia was used in version 1.6.1 on Mechthild and 1.6.2 on the laptop.

\section*{Code Availability}

The \LaTeX{} and Julia source codes for this thesis may be found at:
\begin{center}
\begin{tabular}{l}
  \url{https://github.com/jonas-schulze/master-thesis} \\
  \url{https://github.com/mpimd-csc/DifferentialRiccatiEquations.jl} \\
  \url{https://github.com/mpimd-csc/ParaReal.jl}
\end{tabular}
\end{center}
Additionally, this document as well as the slides used during the defense,
and some of the log files may be found at:
\begin{center}
  \url{https://doi.org/10.5281/zenodo.7843198}
\end{center}
The present version of the document corresponds to git hash
\code{\input{githash.txt}}\unskip.
