\chapter{Implementation and Experimental Results}
\label{sec:results}

\input{content/impl_diffricceq}
\input{content/impl_parareal}

\section{Numerical Results}

\todo[inline]{separate results by sequential/parareal?}

\begin{example}[LTI Rail Profile]
The steel profile benchmark \cite{morwiki_steel} originating from \cite{Benner2005}:
\label{thm:results:rail}
\begin{equation}
\left\{
\begin{aligned}
  E^\T \dot X E &= C^\T C + A^\T X E + E^\T X A - E^\T X BB^\T X E \\
  E^\T X(t_f) E &= \tfrac{1}{100} C^\T C
\end{aligned}
\right.
\end{equation}
where
\begin{equation}
  E, A \in \Rnn,
  \enspace
  B \in \R^{n \times 7},
  \enspace
  C \in \R^{6 \times n}
\end{equation}
and $n=371$.
The problem's time span $[0,4500]$ corresponds to a resolution of \SI{10}{\milli\second},
\ie $t_f = \SI{45}{\second}$.
\end{example}

\subsection{Sequential Solvers}

\begin{figure}[t]
  \missingfigure{Replicate \cite[Figure~6.1]{Lang2017}, $\tau=\SI{112.5}{\milli\second}$}
  \caption{Low-Rank Rosenbrock methods applied to Rail problem}
\end{figure}

\begin{figure}[t]
  \missingfigure{Replicate \cite[Figure~6.6b]{Lang2017}}
  \caption{Numerical rank of low-rank sequential solutions to Rail problem}
\end{figure}

\subsection{Parareal Solvers}
\label{sec:results:parareal}

Looking at \autoref{fig:results:parareal:rail},
there clearly is a problem with the low-rank version of \Ros{2}.
While the sample trajectory $K_{1,77}$ looks ok,
the relative error of the whole $K := B^\T X E$
\begin{equation}
  \frac{\norm{K(t) - K_\text{ref}(t)}_F}{\norm{K_\text{ref}(t)}_F}
\end{equation}
reveals the typical discontinuities at the interval bounds
$t_n = \SI{45}{\second} - n \cdot \SI{100}{\milli\second}$
before convergence is reached,
\cf \autoref{fig:pr:linear}.
Here, this is the case for $n > K = 10$, \ie $t \leq \SI{43.9}{\second}$.
But even for $t > \SI{43.9}{\second}$ there is a noticeable difference between
dense and low-rank versions of the algorithms involving \Ros{2}.
As the dense algorithms converged, so should the low-rank ones.
Only the parareal schemes of order 1/1 behave identically for dense and \ac{LRSIF} storage.
Their errors look similar to~\cite[Fig.~1]{Lang2015}.

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/fig_results_rail.pdf}
  \caption[Parareal method applied to Rail problem]{%
    Several parareal schemes (Rosenbrock methods of given coarse/fine order)
    applied to the problem of \autoref{thm:results:rail},
    running on $N=450$ cores and
    computing up to $K=10$ refinements.
    Each scheme performs
    one coarse step ($\tau=\SI{100}{\milli\second}$) and
    100 fine steps ($\tau=\SI{1}{\milli\second}$) per stage.
    Top: trajectory of $K_{1,77}$ (same as \cite[Fig.~1]{Lang2015}),
    % same as Lang2015, Fig. 1
    % Lang2017, Fig 6.1 used K_{1,71} instead
    bottom: relative error compared to reference solution
    (dense parareal scheme of order 4/4).
    Left: global time span $[\SI{0}{\second}, \SI{45}{\second}]$,
    right: zoom to $[\SI[round-mode=off]{43.2}{\second}, \SI{45}{\second}]$ (highlighted on the left).
  }
  \label{fig:results:parareal:rail}
\end{figure}

\autoref{fig:results:parareal:timeline} shows the timeline diagrams corresponding to the solvers
Due to the problem with the low-rank \Ros{2} solver mentioned in the previous paragraph explains

\begin{figure}[t]
  \missingfigure{}
  \caption[Timeline diagrams for parareal method applied to Rail problem]{%
    Timeline diagrams for the solutions described in \autoref{fig:results:parareal:rail}.
  }
  \label{fig:results:parareal:timeline}
\end{figure}

\begin{figure}[t]
  \missingfigure{Replicate \cite[Figure~6.6b]{Lang2017}}
  \caption{Numerical rank of low-rank parareal solutions to Rail problem}
\end{figure}

\begin{figure}[t]
  \missingfigure{}
  \caption{timeline of reference solution corresponding to \autoref{fig:results:parareal:rail}}
  \label{fig:results:timeline:reference}
\end{figure}

\todo[inline]{
Replicate \cite[Table~6.2]{Lang2017},
Estimate parallel efficiency based on timeline data,
}

\begin{table}[p]
  \centering
  \begin{tabular}{%
    l
    S[table-format=2] % k
    S[table-format=2.2] % warm-up
    S[table-format=-1.2] % ramp-up
    S[table-format=1.2] % G
    S[table-format=3.2] % F
    S[table-format=4.2] % par
    S[table-format=4.2] % par est
    S[round-precision=3, round-minimum=0.001, table-format=<1.3, scientific-notation=fixed, fixed-exponent=0] % err
  }
    \toprule
    Solver &
    {$k_N$} &
    {$\twarmup$} &
    {$\trampup$} &
    {$t_G$} &
    {$t_F$} &
    {$\tpar$} &
    {$\hattpar$} &
    {$\abs*{\frac{\hattpar-\tpar}{\tpar}}$} \\
    \midrule
    %TODO: Add uncertainties for low-rank t_F and t_G?
    \input{tables/warmup450_lr.tex}
    \midrule
    \input{tables/warmup450_de.tex}
    \midrule
    \input{tables/warmup450_ref.tex}
    \bottomrule
  \end{tabular}
  \caption[Timeline measurements for parareal algorithm, $N=450$, $K=10$]{%
    Timeline measurements for parareal algorithm, $N=450$, $K=10$.
    All measurements and estimates are as in \autoref{tab:impl:warmup}.
    The first column denotes the parareal scheme (coarse/fine order).
  }
  \label{tab:results:warmup}
\end{table}

\begin{table}[p]
  \centering
  \begin{tabular}{%
    l
    S[table-format=4.2] % par
    S[table-format=6.2] % seq est
    S[table-format=2.2] % speedup
    S[round-precision=3, round-minimum=0.001, table-format=1.3, scientific-notation=fixed, fixed-exponent=0] % efficiency
  }
    \toprule
    Solver &
    {$\tpar$} &
    {$\hattseq$} &
    {$\frac{\hattseq}{\tpar}$} &
    {$\frac{\hattseq}{N\cdot\tpar}$} \\
    \midrule
    \input{tables/speedup450_lr.tex}
    \midrule
    \input{tables/speedup450_de.tex}
    \midrule
    \input{tables/speedup450_ref.tex}
    \bottomrule
  \end{tabular}
  \caption[Speed-up and parallel efficiency of parareal algorithm, $N=450$, $K=10$]{%
    Speed-up and parallel efficiency of parareal algorithm, $N=450$, $K=10$.
    This table complements \autoref{tab:results:warmup}.
    The sequential runtime $\hattseq$ is estimated as $\sum_{n=1}^N t_F(n, k_n-1)$,
    \ie the total runtime of the last $F(U_{n-1}^*)$ computed.
    The parallel efficiency is evaluated for $N$ processors.
  }
\end{table}
